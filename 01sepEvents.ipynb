{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary\n",
    "\n",
    "train_direction = 0 south, 1 north\n",
    "train_type = 0 Local, 1 Limited, 2 Bullet\n",
    "train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import operator\n",
    "\n",
    "from func import *\n",
    "\n",
    "# inline plot\n",
    "%matplotlib inline\n",
    "#%%javascript\n",
    "#IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%load 'data/raw-twt2016-01-26-14/21/09.csv'\n",
    "df = pd.read_csv(\"data/raw-twt2016-01-26-14-21-09.csv\",sep='\\t',error_bad_lines=False)\n",
    "# df.head(5)\n",
    "print len(df.index)\n",
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Cleanin' the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill in blank hashtags\n",
    "df = df.where((pd.notnull(df)), np.nan)\n",
    "df[\"hashtags\"].fillna('')\n",
    "\n",
    "# Add some date/time things\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors='coerce')\n",
    "\n",
    "df[\"day_of_week\"] = df[\"created_at\"].apply(lambda x: x.weekday())\n",
    "df[\"day_of_month\"] = df[\"created_at\"].apply(lambda x: x.day)\n",
    "df[\"month\"] = df[\"created_at\"].apply(lambda x: x.month)\n",
    "df[\"isRushHour\"] = df[\"created_at\"].apply(lambda x: get_time_of_day(x))\n",
    "\n",
    "# del tod_Dummy['shutdown']\n",
    "\n",
    "# df['in_reply_to_screen_name'].fillna(-1)\n",
    "# df['in_reply_to_status_id'].fillna(-1)\n",
    "# df['in_reply_to_user_id'].fillna(-1)\n",
    "# df['retweeted_status'].fillna(-1)\n",
    "# df['retweeted'].fillna(-1)\n",
    "df['retweet_count'].fillna(np.nan)\n",
    "df['favorite_count'].fillna(np.nan)\n",
    "df[\"hashtags\"].fillna(np.nan)\n",
    "df[\"hashtags\"] = df[\"hashtags\"].apply(lambda x: str(x)[1:-1])\n",
    "df.loc[df[\"hashtags\"]=='a',\"hashtags\"] = ''\n",
    "#list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Potentially remove, just cleaning for analysis sake\n",
    "del df['Unnamed: 0']\n",
    "# del df['truncated']\n",
    "del df['user_mentions']\n",
    "del df['urls']\n",
    "del df['source']\n",
    "del df['lang']\n",
    "del df['place']\n",
    "del df['favorited']\n",
    "del df['media']\n",
    "del df['user']\n",
    "\n",
    "# More likely to remove\n",
    "del df['in_reply_to_status_id']\n",
    "del df['in_reply_to_user_id']\n",
    "del df['retweeted']\n",
    "del df['retweeted_status']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start getting some more detailed data from the trips as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['favorite_count'] = df['favorite_count'].astype(np.int64)\n",
    "# df['retweet_count'] = df['retweet_count'].astype(np.int64)\n",
    "# df['text'] = df['text'].astype(str)\n",
    "# df['id'] = df['id'].astype(np.int64)\n",
    "# df['day_of_week'] = df['day_of_week'].astype(np.int64)\n",
    "# df['day_of_month'] = df['day_of_month'].astype(np.int64)\n",
    "# df['month'] = df['month'].astype(np.int64)\n",
    "# df['time_of_day'] = df['time_of_day'].astype(np.int64)\n",
    "df.loc[df[\"hashtags\"]=='on',\"hashtags\"] = np.nan\n",
    "df.convert_objects(convert_numeric=True)\n",
    "df.dtypes\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull out potential trains from both hashtags and text\n",
    "df[\"topic_train\"] = df[\"text\"].apply(lambda x: check_train_id(x))\n",
    "df[\"topic_train\"] = df[\"topic_train\"].apply(lambda x: str(x)[1:-1])\n",
    "df[\"topic_train\"].fillna(np.nan)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a word about the below code.\n",
    "In the accompanying `func.py` there is a function called parse_train that returns a `pandas.Series` object. For some reason, when it's returned from a map or apply, it seems to get cast as a string. When applied to a list or a dataframe, this string gets turned into a single field in the row, OR divided into several rows, throwing the count off.\n",
    "\n",
    "To get around this, I return the results of the parse_train function and then CAST it back to a series. This adds a weird 0 index, which I delete. I then fill in the plethora of NaNs and recombine it with the primary dataframe.\n",
    "\n",
    "For context, previous iterations included\n",
    "`df['topic_train'].apply(lambda x:parse_train(x))`\n",
    "which would return a pd.Series object with `str` versions of the returned pd.Series from `parse_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret = []\n",
    "\n",
    "def parse_train(t):\n",
    "# Revised this function to work with categorical variables\n",
    "# x should be a list with train codes eg 123\n",
    "# {\"id\": \"123\", \"type:\" \"bullet\", direction: \"south\"}\n",
    "\n",
    "    try:\n",
    "        s = t['topic_train'].split(',')\n",
    "    except:\n",
    "        return t['topic_train']\n",
    "    if s[0] == '':\n",
    "        return np.nan\n",
    "    for x in s:\n",
    "        q = {}\n",
    "        x = str(x)\n",
    "        x = re.sub('[^0-9]','', x)\n",
    "        if len(x)<3: continue\n",
    "\n",
    "        # 1 = north, 0 = south\n",
    "        q[\"t_northbound\"] = 1 if int(x[2]) in [1,3,5,7,9] else 0\n",
    "        q['t_limited'] = 0\n",
    "        q['t_bullet'] = 0\n",
    "        \n",
    "        if x[0] == '1':\n",
    "            q['t_limited'] = 0\n",
    "        elif x[0] == '2':\n",
    "            q[\"t_limited\"] = 1 # limited\n",
    "        elif x[0] == '3':\n",
    "            q[\"t_bullet\"] = 1 # bullet\n",
    "        else:\n",
    "            q['t_limited'] = 0\n",
    "\n",
    "        ret.append({'tweet_id': t['id'],\n",
    "                    'timestamp': t['created_at'], \n",
    "                    'train_id': int(x),\n",
    "                    't_northbound':q[\"t_northbound\"], \n",
    "                    't_limited': q[\"t_limited\"],\n",
    "                    't_bullet': q['t_bullet']})\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's then filter those train topics into details\n",
    "# Btw this is jank as fuck.\n",
    "\n",
    "# red = df[['id','created_at','topic_train']]\n",
    "red = df.apply(lambda x:parse_train(x),axis=1)\n",
    "print \"red return:\",len(red)\n",
    "print \"ret return,\",len(ret)\n",
    "#red\n",
    "tf = pd.DataFrame(ret)\n",
    "tf.head(5)\n",
    "\n",
    "#events = pd.DataFrame([pd.Series(x) for x in red.apply(parse_train)])\n",
    "#events\n",
    "#del new.iloc[0]\n",
    "#new.fillna('')\n",
    "#df.combine_first(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.loc[df['topic_train'] != '',['topic_train','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge on tweet ID,\n",
    "df = df.merge(tf, left_on='id',right_on='tweet_id',how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Okay, let's try and get a yae or nae to delay and see our hit rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only events that have train mentioned\n",
    "trains = df[df['train_id'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d\n",
    "filename = \"./data/formated_twts.csv\"\n",
    "df.to_csv(filename, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The next step: manually clean the data.\n",
    "\n",
    "This is what the caltrain is for.\n",
    "\n",
    "The fields:\n",
    "- `is_delay`: 1 = true, 0 false (ignore 0)\n",
    "- `delay_minor`: >=10min = 1 else 0\n",
    "- `delay_med`: < 10m & >=20m = 1 else 0\n",
    "- `delay_major`: < 20m & >=40m = 1 else 0\n",
    "- `delay_catastrophic`:< 40m = 1 else 0\n",
    "- `is_backlog`: multiple trains IN SAME DIRECTION delayed or passing else 0\n",
    "- `is_canceled`: Train Canceled else 0\n",
    "- `is_passing`: Train indicates passing/rescheduling else 0\n",
    "- `is_accident`: Mention of accident, vehicle on tracks, or fatality else 0\n",
    "- `is_mechanical`: Mention of mechanical issue else 0\n",
    "- `is_customer`: Mention of rider-caused disruption (eg fare evasion) else 0\n",
    "\n",
    "NOTE: `is_delay` with no indication of magnitude means UNKNOWN but reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
