{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary\n",
    "\n",
    "train_direction = 0 south, 1 north\n",
    "train_type = 0 Local, 1 Limited, 2 Bullet\n",
    "train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import operator\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from func import *\n",
    "\n",
    "# inline plot\n",
    "%matplotlib inline\n",
    "#%%javascript\n",
    "#IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'created_at',\n",
       " 'favorite_count',\n",
       " 'favorited',\n",
       " 'hashtags',\n",
       " 'id',\n",
       " 'in_reply_to_screen_name',\n",
       " 'in_reply_to_status_id',\n",
       " 'in_reply_to_user_id',\n",
       " 'lang',\n",
       " 'media',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'retweeted',\n",
       " 'retweeted_status',\n",
       " 'source',\n",
       " 'text',\n",
       " 'truncated',\n",
       " 'urls',\n",
       " 'user',\n",
       " 'user_mentions']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%load 'data/raw-twt2016-01-26-14/21/09.csv'\n",
    "df = pd.read_csv(\"data/raw-twt2016-01-26-14-21-09.csv\",sep='\\t',error_bad_lines=False)\n",
    "# df.head(5)\n",
    "print len(df.index)\n",
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Cleanin' the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   error  rush_evening  rush_morning  workday\n",
      "0      1             0             0        0\n",
      "1      0             1             0        0\n",
      "2      0             1             0        0\n",
      "3      0             1             0        0\n",
      "4      0             1             0        0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'shutdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dd98f2448e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtod_Dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_of_day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtod_Dummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtod_Dummy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shutdown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# df['in_reply_to_screen_name'].fillna(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/albarron/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1341\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;31m# delete from the caches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/albarron/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3157\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m         \"\"\"\n\u001b[0;32m-> 3159\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0mis_deleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/albarron/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1690\u001b[0m                 raise ValueError('tolerance argument only valid if using pad, '\n\u001b[1;32m   1691\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shutdown'"
     ]
    }
   ],
   "source": [
    "# Fill in blank hashtags\n",
    "df = df.where((pd.notnull(df)), np.nan)\n",
    "df[\"hashtags\"].fillna('')\n",
    "\n",
    "# Add some date/time things\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors='coerce')\n",
    "\n",
    "df[\"day_of_week\"] = df[\"created_at\"].apply(lambda x: x.weekday())\n",
    "df[\"day_of_month\"] = df[\"created_at\"].apply(lambda x: x.day)\n",
    "df[\"month\"] = df[\"created_at\"].apply(lambda x: x.month)\n",
    "df[\"time_of_day\"] = df[\"created_at\"].apply(lambda x: get_time_of_day(x))\n",
    "\n",
    "tod_Dummy = pd.get_dummies(df['time_of_day'])\n",
    "print(tod_Dummy.head(5))\n",
    "# del tod_Dummy['shutdown']\n",
    "\n",
    "# df['in_reply_to_screen_name'].fillna(-1)\n",
    "# df['in_reply_to_status_id'].fillna(-1)\n",
    "# df['in_reply_to_user_id'].fillna(-1)\n",
    "# df['retweeted_status'].fillna(-1)\n",
    "# df['retweeted'].fillna(-1)\n",
    "df['retweet_count'].fillna(np.nan)\n",
    "df['favorite_count'].fillna(np.nan)\n",
    "df[\"hashtags\"].fillna(np.nan)\n",
    "df[\"hashtags\"] = df[\"hashtags\"].apply(lambda x: str(x)[1:-1])\n",
    "df.loc[df[\"hashtags\"]=='a',\"hashtags\"] = ''\n",
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Potentially remove, just cleaning for analysis sake\n",
    "del df['Unnamed: 0']\n",
    "del df['truncated']\n",
    "del df['user_mentions']\n",
    "del df['urls']\n",
    "del df['source']\n",
    "del df['lang']\n",
    "del df['place']\n",
    "del df['favorited']\n",
    "del df['media']\n",
    "del df['user']\n",
    "\n",
    "# More likely to remove\n",
    "del df['in_reply_to_status_id']\n",
    "del df['in_reply_to_user_id']\n",
    "del df['retweeted']\n",
    "del df['retweeted_status']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot(x='created_at', y='day_of_week', kind='hist')\n",
    "# fdf = df[[\"created_at\",\"id\",\"text\",\"hashtags\"]]\n",
    "# str(fdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start getting some more detailed data from the trips as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df['favorite_count'] = df['favorite_count'].astype(np.int64)\n",
    "# df['retweet_count'] = df['retweet_count'].astype(np.int64)\n",
    "# df['text'] = df['text'].astype(str)\n",
    "# df['id'] = df['id'].astype(np.int64)\n",
    "# df['day_of_week'] = df['day_of_week'].astype(np.int64)\n",
    "# df['day_of_month'] = df['day_of_month'].astype(np.int64)\n",
    "# df['month'] = df['month'].astype(np.int64)\n",
    "# df['time_of_day'] = df['time_of_day'].astype(np.int64)\n",
    "df.loc[df[\"hashtags\"]=='on',\"hashtags\"] = np.nan\n",
    "df.convert_objects(convert_numeric=True)\n",
    "df.dtypes\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pull out potential trains from both hashtags and text\n",
    "df[\"topic_train\"] = df[\"text\"].apply(lambda x: check_train_id(x))\n",
    "df[\"topic_train\"] = df[\"topic_train\"].apply(lambda x: str(x)[1:-1])\n",
    "df[\"topic_train\"].fillna(np.nan)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.pivot_table(\n",
    "#   df,values='values',\n",
    "#   index=['month'],\n",
    "#   columns=['day_of_week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a word about the below code.\n",
    "In the accompanying `func.py` there is a function called parse_train that returns a `pandas.Series` object. For some reason, when it's returned from a map or apply, it seems to get cast as a string. When applied to a list or a dataframe, this string gets turned into a single field in the row, OR divided into several rows, throwing the count off.\n",
    "\n",
    "To get around this, I return the results of the parse_train function and then CAST it back to a series. This adds a weird 0 index, which I delete. I then fill in the plethora of NaNs and recombine it with the primary dataframe.\n",
    "\n",
    "For context, previous iterations included\n",
    "`df['topic_train'].apply(lambda x:parse_train(x))`\n",
    "which would return a pd.Series object with `str` versions of the returned pd.Series from `parse_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret = []\n",
    "\n",
    "def parse_train(t):\n",
    "# x should be a list with train codes eg 123\n",
    "# {\"id\": \"123\", \"type:\" \"bullet\", direction: \"south\"}\n",
    "\n",
    "    try:\n",
    "        s = t['topic_train'].split(',')\n",
    "    except:\n",
    "        return t['topic_train']\n",
    "    if s[0] == '':\n",
    "#         print \"\"\n",
    "        return np.nan\n",
    "    for x in s:\n",
    "#         print \"Iter\",x[1:-1]\n",
    "        q = {}\n",
    "        # Check train id\n",
    "#         x = parse_train_id(x)\n",
    "        x = str(x)\n",
    "        x = re.sub('[^0-9]','', x)\n",
    "        if len(x)<3: continue\n",
    "\n",
    "        # 1 = north, 0 = south\n",
    "        q[\"t_northbound\"] = 1 if int(x[2]) in [1,3,5,7,9] else 0\n",
    "        q['t_limited'] = 0\n",
    "        q['t_bullet'] = 0\n",
    "        \n",
    "        if x[0] == '1':\n",
    "            q['t_limited'] = 0\n",
    "        elif x[0] == '2':\n",
    "            q[\"t_limited\"] = 1 # limited\n",
    "        elif x[0] == '3':\n",
    "            q[\"t_bullet\"] = 1 # bullet\n",
    "        else:\n",
    "            q['t_limited'] = 0\n",
    "\n",
    "        ret.append({'tweet_id': t['id'],\n",
    "                    'timestamp': t['created_at'], \n",
    "                    'train_id': int(x),\n",
    "                    't_northbound':q[\"t_northbound\"], \n",
    "                    't_limited': q[\"t_limited\"],\n",
    "                    't_bullet': q['t_bullet']})\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's then filter those train topics into details\n",
    "# Btw this is jank as fuck.\n",
    "\n",
    "# red = df[['id','created_at','topic_train']]\n",
    "red = df.apply(lambda x:parse_train(x),axis=1)\n",
    "print \"red return:\",len(red)\n",
    "print \"ret return,\",len(ret)\n",
    "#red\n",
    "tf = pd.DataFrame(ret)\n",
    "tf.head(5)\n",
    "\n",
    "#events = pd.DataFrame([pd.Series(x) for x in red.apply(parse_train)])\n",
    "#events\n",
    "#del new.iloc[0]\n",
    "#new.fillna('')\n",
    "#df.combine_first(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.loc[df['topic_train'] != '',['topic_train','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(tf, left_on='id',right_on='tweet_id',how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(['time_of_day','month']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(x='time_of_day',y='day_of_week',kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.scatter_matrix(df,alpha=0.1,figsize=(15,15), diagonal='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('month').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['train_id'] > 0].groupby('day_of_week').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['train_id'] > 0].groupby('month').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['train_id'] > 0].groupby('time_of_day').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
